"""chestxrays.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VT3C9dhmxHVw1RZRJevhLVPS5Um3XdRR
"""


import gdown



print("---------------------------------Started Downloading Dataset---------------------------------")
url = "https://drive.google.com/u/0/uc?id=1TvNW_EAKekz9UAUkT9MT_Z6kFMVrb9-H&export=download"
output = "file_name.zip"
gdown.download(url, output, quiet=False)

import zipfile
with zipfile.ZipFile(output, 'r') as zip_ref:
    zip_ref.extractall()

print("---------------------------------Completed Downloading Dataset---------------------------------")

import PIL.Image as Image
import matplotlib.pylab as plt
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
import os 
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential,Model
import tensorflow as tf
import random as rn
import cv2                  
from tqdm import tqdm
from random import shuffle  
from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
from keras import backend as K

img_size = 224
batch_size = 32

datagen = ImageDataGenerator(rescale=1/255.,
                            zoom_range=0.2,
                            horizontal_flip=True,
                            validation_split=0.15)
print("\n")
train_generator = datagen.flow_from_directory('chest_xray/train',
                                              target_size=(img_size,img_size),
                                              batch_size=batch_size,
                                              shuffle=True,
                                              subset='training',
                                              #color_mode='grayscale',
                                              class_mode='categorical')

val_generator = datagen.flow_from_directory('chest_xray/train',
                                            target_size=(img_size,img_size),
                                            batch_size=batch_size,
                                            shuffle=False,
                                            subset='validation',
                                            #color_mode='grayscale',
                                            class_mode='categorical')
print("\n")

if not os.path.exists("outputs/chestXrayDataset"):
    os.makedirs("outputs/chestXrayDataset")


label = [k for k in train_generator.class_indices]
samples = train_generator.__next__()
images = samples[0]
titles = samples[1]
plt.figure(figsize=(20,20))

for i in range(15):
    plt.subplot(5,5,i+1)
    plt.subplots_adjust(hspace=0.3,wspace=0.3)
    plt.imshow(images[i])
    plt.title(f"Class: {label[np.argmax(titles[i],axis=0)]}")
    plt.axis("off")
plt.savefig("outputs/chestXrayDataset/chest_xray_sample.png")
print("\n")
"""# VGG16"""
print("---------------------------------Creating VGG16 Model---------------------------------")

from tensorflow.keras.applications.vgg16 import VGG16
base_model=VGG16(include_top=False,weights='imagenet',input_shape=(img_size,img_size,3))
base_model.trainable = False 
from tensorflow.keras import layers, models
flatten_layer = layers.Flatten()
dense_layer_1 = layers.Dense(50, activation='relu')
dense_layer_2 = layers.Dense(20, activation='relu')
prediction_layer = layers.Dense(2, activation='softmax')


Vgg_model = models.Sequential([
    base_model,
    flatten_layer,
    dense_layer_1,
    dense_layer_2,
    prediction_layer
])
Vgg_model.summary()
print("\n")
print("--------------------------------- VGG16 Model with Adam Optimizer---------------------------------")

"""## Adam"""

beta1 = 0.9
beta2 = 0.99
epsilonE = 1e-06

vggadam=Vgg_model
from tensorflow.keras.callbacks import EarlyStopping
adam1 = tf.keras.optimizers.Adam(
    learning_rate = 0.001,
    beta_1 = beta1,
    beta_2 = beta2,
    epsilon = epsilonE,
    amsgrad=False,
 
)
vggadam.compile(
    optimizer=adam1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)

es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)

# , validation_split=0.2
historyvggadam = vggadam.fit(train_generator, epochs=50,validation_data=val_generator, batch_size=32, callbacks=[es])

vggadamval=vggadam.evaluate(val_generator)
print("\n")
print("VGG16 Model - Adam Optimizer Accuracy - ",vggadamval[1]*100 )
vggadamval

"""## Adagrad"""
print("\n")
print("--------------------------------- VGG16 Model with Adagrad Optimizer---------------------------------")

vggada=Vgg_model
adagrad1 = tf.keras.optimizers.Adagrad(
    learning_rate = 0.001,
    initial_accumulator_value = 0.1,
    epsilon = epsilonE,
)

vggada.compile(
    optimizer=adagrad1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
historyvggada = vggada.fit(train_generator, epochs=50,validation_data=val_generator, batch_size=32, callbacks=[es])

vggadaval=vggada.evaluate(val_generator)
print("\n")
print("VGG16 Model - Adagrad Optimizer Accuracy - ",vggadaval[1]*100 )

vggadaval

"""## RMSProp"""
print("\n")
print("--------------------------------- VGG16 Model with RMSProp Optimizer---------------------------------")

# RMSProp
vggrms = Vgg_model
rmsprop1 = tf.keras.optimizers.RMSprop(
    learning_rate = 0.001,
    rho = 0.9,
    momentum = 0.0,
    epsilon = epsilonE,
    centered=False,
)
vggrms.compile(
    optimizer=rmsprop1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
historyvggrms = vggrms.fit(train_generator, epochs=50,validation_data=val_generator, batch_size=32, callbacks=[es])

vggrmsval=vggrms.evaluate(val_generator)
print("\n")
print("VGG16 Model - RMSProp Optimizer Accuracy - ",vggrmsval[1]*100 )

vggrmsval

"""## SGD"""
print("\n")
print("--------------------------------- VGG16 Model with SGD Optimizer---------------------------------")

vggsgd = Vgg_model
momentum1 = tf.keras.optimizers.SGD(
    learning_rate = 0.01,
    momentum = beta1,
    nesterov = False,
)

vggsgd.compile(
    optimizer=momentum1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
historyvggsgd = vggsgd.fit(train_generator, epochs=50,validation_data=val_generator, batch_size=32, callbacks=[es])

vggsgdval=vggsgd.evaluate(val_generator)
print("\n")
print("VGG16 Model - SGD Optimizer Accuracy - ",vggsgdval[1]*100 )

"""## Plots"""

import seaborn as sns
classifiers = [vggadamval , vggadaval ,vggrmsval ,vggsgdval]
cv_results_res = []
for i in classifiers :
    cv_results_res.append(i[1])
cv_results_res = pd.DataFrame({"Evaluate":cv_results_res,"Network":["vggAdam","vggAdagrad","vggRMS",
"vggSGD"]})

cv_results_res

# use seaborn to create a barplot
sns.set(style="whitegrid")
ax = sns.barplot(x="Network", y="Evaluate", data=cv_results_res)

# add labels to the plot
ax.set_title("Evaluation Scores for Different Optimizers for VGG16")
ax.set_xlabel("Network")
ax.set_ylabel("Accuracy")

# display the plot
plt.savefig("outputs/chestXrayDataset/vgg16_optimizer_evaluation.png")
plt.show()

"""## Loss Plots"""

# Plot training & validation loss values
plt.plot(historyvggadam.history['loss'])
plt.plot(historyvggada.history['loss'])
plt.plot(historyvggrms.history['loss'])
plt.plot(historyvggsgd.history['loss'])
plt.title('VGG16 Model Training Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='upper right')
plt.savefig("outputs/chestXrayDataset/vgg16_training_loss.png")
plt.show()

# Plot training & validation loss values
plt.plot(historyvggadam.history['val_loss'])
plt.plot(historyvggada.history['val_loss'])
plt.plot(historyvggrms.history['val_loss'])
plt.plot(historyvggsgd.history['val_loss'])
plt.title('VGG16 Model Validation Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='upper right')
plt.savefig("outputs/chestXrayDataset/vgg16_validation_loss.png")
plt.show()

"""## Accuracy Plots"""

# Plot training & validation loss values
plt.plot(historyvggadam.history['accuracy'])
plt.plot(historyvggada.history['accuracy'])
plt.plot(historyvggrms.history['accuracy'])
plt.plot(historyvggsgd.history['accuracy'])
plt.title('VGG16 Model Training Accuracy')
plt.ylabel('accuracy')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='lower right')
plt.savefig('outputs/chestXrayDataset/vgg16_training_accuracy.png')
plt.show()

# Plot training & validation loss values
plt.plot(historyvggadam.history['val_accuracy'])
plt.plot(historyvggada.history['val_accuracy'])
plt.plot(historyvggrms.history['val_accuracy'])
plt.plot(historyvggsgd.history['val_accuracy'])
plt.title('VGG16 Model Validation Accuracy')
plt.ylabel('accuracy')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='lower right')
plt.savefig('outputs/chestXrayDataset/vgg16_validation_accuracy.png')
plt.show()

"""## Whisker Plot"""

import seaborn as sns
import pandas as pd
optimizer =['Adam', 'Adagrad','RMSprop','SGD']
histories =[historyvggadam,historyvggada,historyvggrms,historyvggsgd]
acc_data=[]
for i in range(len(optimizer)):
    acc = histories[i].history['val_accuracy']
    acc_data.append(acc)
  
fig, ax = plt.subplots()
ax.boxplot(acc_data, labels=[str(i) for i in optimizer])
ax.set_ylabel('Accuracy')
ax.set_xlabel('Optimizers')
ax.set_title('VGG16 Model - Validation Accuracy by Optimizer')
plt.savefig('outputs/chestXrayDataset/vgg16_validation_accuracy_whiskerplot.png')
plt.show()

"""# ResNet50"""
print("\n")
print("--------------------------------- ResNet50 Model --------------------------------")
from tensorflow.keras.applications.resnet50 import ResNet50
base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(img_size, img_size, 3))
base_model.trainable = False

from tensorflow.keras import layers, models
flatten_layer = layers.Flatten()
dense_layer_1 = layers.Dense(50, activation='relu')
dense_layer_2 = layers.Dense(20, activation='relu')
prediction_layer = layers.Dense(2, activation='softmax')

ResNet_model = models.Sequential([
    base_model,
    flatten_layer,
    dense_layer_1,
    dense_layer_2,
    prediction_layer
])
ResNet_model.summary()

beta1 = 0.9
beta2 = 0.99
epsilonE = 1e-06

"""## Adam"""
print("\n")
print("--------------------------------- ResNet50 Model with Adam Optimizer---------------------------------")
resnet_adam = ResNet_model
adam1 = tf.keras.optimizers.Adam(
    learning_rate = 0.001,
    beta_1 = beta1,
    beta_2 = beta2,
    epsilon = epsilonE,
    amsgrad=False,
)

resnet_adam.compile(
    optimizer=adam1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
history_resnet_adam = resnet_adam.fit(train_generator, epochs=50, validation_data=val_generator, batch_size=32, callbacks=[es])

resnet_adam_val = resnet_adam.evaluate(val_generator)
print("\n")
print("ResNet50 Model - Adam Optimizer Accuracy - ", resnet_adam_val[1]*100)
resnet_adam_val

"""## Adagrad"""
print("\n")
print("--------------------------------- ResNet50 Model with Adagrad Optimizer---------------------------------")
resnet_ada=ResNet_model
adagrad1 = tf.keras.optimizers.Adagrad(
    learning_rate = 0.001,
    initial_accumulator_value = 0.1,
    epsilon = epsilonE,
)

resnet_ada.compile(
    optimizer=adagrad1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
history_resnet_ada = resnet_ada.fit(train_generator, epochs=50,validation_data=val_generator, batch_size=32, callbacks=[es])

resnet_ada_val = resnet_ada.evaluate(val_generator)
print("\n")
print("ResNet50 Model - Adagrad Optimizer Accuracy - ", resnet_ada_val[1]*100)
resnet_ada_val

"""## RMSProp"""

# RMSProp
print("\n")
print("--------------------------------- ResNet50 Model with RMSProp Optimizer---------------------------------")
resnet_rms = ResNet_model
rmsprop1 = tf.keras.optimizers.RMSprop(
    learning_rate = 0.001,
    rho = 0.9,
    momentum = 0.0,
    epsilon = epsilonE,
    centered=False,
)
resnet_rms.compile(
    optimizer=rmsprop1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
history_resnet_rms = resnet_rms.fit(train_generator, epochs=50,validation_data=val_generator, batch_size=32, callbacks=[es])

resnet_rms_val = resnet_rms.evaluate(val_generator)
print("\n")
print("ResNet50 Model - RMSProp Optimizer Accuracy - ", resnet_rms_val[1]*100)
resnet_rms_val

"""## SGD"""
print("\n")
print("--------------------------------- ResNet50 Model with SGD Optimizer---------------------------------")
resnet_sgd = ResNet_model
momentum1 = tf.keras.optimizers.SGD(
    learning_rate = 0.01,
    momentum = beta1,
    nesterov = False,
)

resnet_sgd.compile(
    optimizer=momentum1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
history_resnet_sgd = resnet_sgd.fit(train_generator, epochs=50,validation_data=val_generator, batch_size=32, callbacks=[es])

resnet_sgd_val = resnet_sgd.evaluate(val_generator)
print("\n")
print("ResNet50 Model - SGD Optimizer Accuracy - ", resnet_sgd_val[1]*100)
resnet_sgd_val

"""## Plots"""

import seaborn as sns
classifiers = [resnet_adam_val , resnet_ada_val ,resnet_rms_val ,resnet_sgd_val]
cv_results_res = []
for i in classifiers :
    cv_results_res.append(i[1])
cv_results_res = pd.DataFrame({"Evaluate":cv_results_res,"Network":["resNetAdam","resNetAdagrad","resNetRMS",
"resNetGD"]})

cv_results_res

# use seaborn to create a barplot
sns.set(style="whitegrid")
ax = sns.barplot(x="Network", y="Evaluate", data=cv_results_res)

# add labels to the plot
ax.set_title("Evaluation Scores for Different Optimizers for ResNet50")
ax.set_xlabel("Network")
ax.set_ylabel("Accuracy")
plt.savefig("outputs/chestXrayDataset/resnet50_evaluation_scores.png")
# display the plot
plt.show()

"""## Loss Plots"""

# Plot training & validation loss values
plt.plot(history_resnet_adam.history['loss'])
plt.plot(history_resnet_ada.history['loss'])
plt.plot(history_resnet_rms.history['loss'])
plt.plot(history_resnet_sgd.history['loss'])
plt.title('ResNet50 Model Training Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='upper right')
plt.savefig("outputs/chestXrayDataset/resnet50_training_loss.png")
plt.show()

# Plot training & validation loss values
plt.plot(history_resnet_adam.history['val_loss'])
plt.plot(history_resnet_ada.history['val_loss'])
plt.plot(history_resnet_rms.history['val_loss'])
plt.plot(history_resnet_sgd.history['val_loss'])
plt.title('ResNet50 Model Validation Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='upper right')
plt.savefig("outputs/chestXrayDataset/resnet50_validation_loss.png")
plt.show()

"""## Accuracy Plots"""

# Plot training & validation loss values
plt.plot(history_resnet_adam.history['accuracy'])
plt.plot(history_resnet_ada.history['accuracy'])
plt.plot(history_resnet_rms.history['accuracy'])
plt.plot(history_resnet_sgd.history['accuracy'])
plt.title('ResNet50 Model Training Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='lower right')
plt.savefig("outputs/chestXrayDataset/resnet50_training_accuracy.png")
plt.show()

# Plot training & validation loss values
plt.plot(history_resnet_adam.history['val_accuracy'])
plt.plot(history_resnet_ada.history['val_accuracy'])
plt.plot(history_resnet_rms.history['val_accuracy'])
plt.plot(history_resnet_sgd.history['val_accuracy'])
plt.title('ResNet50 Model Validation Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='lower right')
plt.savefig("outputs/chestXrayDataset/resnet50_validation_accuracy.png")
plt.show()

"""## Whisket Plot"""

import seaborn as sns
import pandas as pd
optimizer =['Adam', 'Adagrad','RMSprop','SGD']
histories =[history_resnet_adam,history_resnet_ada,history_resnet_rms,history_resnet_sgd]
acc_data=[]
for i in range(len(optimizer)):
    acc = histories[i].history['val_accuracy']
    acc_data.append(acc)
  
fig, ax = plt.subplots()
ax.boxplot(acc_data, labels=[str(i) for i in optimizer])
ax.set_ylabel('Accuracy')
ax.set_xlabel('Optimizers')
ax.set_title('ResNet50 Model - Validation Accuracy by Optimizer')
plt.savefig("outputs/chestXrayDataset/resnet50_validation_accuracy_whiskerplot.png")
plt.show()

"""# InceptionResNetV2"""
print("\n")
print("--------------------------------- InceptionResNetV2 Model ---------------------------------")
from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2
base_model = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(img_size, img_size, 3))
base_model.trainable = False

from tensorflow.keras import layers, models
flatten_layer = layers.Flatten()
dense_layer_1 = layers.Dense(50, activation='relu')
dense_layer_2 = layers.Dense(20, activation='relu')
prediction_layer = layers.Dense(2, activation='softmax')

InceptionResNet_model = models.Sequential([
    base_model,
    flatten_layer,
    dense_layer_1,
    dense_layer_2,
    prediction_layer
])
InceptionResNet_model.summary()

beta1 = 0.9
beta2 = 0.99
epsilonE = 1e-06

"""## Adam"""
print("\n")
print("--------------------------------- InceptionResNetV2 Model with Adam Optimizer---------------------------------")
inception_resnet_adam = InceptionResNet_model
import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping
adam1 = tf.keras.optimizers.Adam(
    learning_rate = 0.001,
    beta_1 = beta1,
    beta_2 = beta2,
    epsilon = epsilonE,
    amsgrad=False,
)

inception_resnet_adam.compile(
    optimizer=adam1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5, restore_best_weights=True)
history_inception_resnet_adam = inception_resnet_adam.fit(train_generator, epochs=50, validation_data=val_generator, batch_size=32, callbacks=[es])

inception_resnet_adam_val = inception_resnet_adam.evaluate(val_generator)
print("\n")
print("InceptionResNetV2 Model - Adam Optimizer Accuracy - ", inception_resnet_adam_val[1]*100)
inception_resnet_adam_val

"""## Adagrad"""
print("\n")
print("--------------------------------- InceptionResNetV2 Model with Adagrad Optimizer---------------------------------")
inception_resnet_ada=InceptionResNet_model
adagrad1 = tf.keras.optimizers.Adagrad(
    learning_rate = 0.001,
    initial_accumulator_value = 0.1,
    epsilon = epsilonE,
)

inception_resnet_ada.compile(
    optimizer=adagrad1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
history_inception_resnet_ada = inception_resnet_ada.fit(train_generator, epochs=50,validation_data=val_generator, batch_size=32, callbacks=[es])

inception_resnet_ada_val = inception_resnet_ada.evaluate(val_generator)
print("\n")
print("InceptionResNetV2 Model - Adagrad Optimizer Accuracy - ", inception_resnet_ada_val[1]*100)
inception_resnet_ada_val

"""## RMSProp"""
print("\n")
print("--------------------------------- InceptionResNetV2 Model with RMSProp Optimizer---------------------------------")
# RMSProp
inception_resnet_rms = InceptionResNet_model
rmsprop1 = tf.keras.optimizers.RMSprop(
    learning_rate = 0.001,
    rho = 0.9,
    momentum = 0.0,
    epsilon = epsilonE,
    centered=False,
)
inception_resnet_rms.compile(
    optimizer=rmsprop1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
history_inception_resnet_rms = inception_resnet_rms.fit(train_generator, epochs=50,validation_data=val_generator, batch_size=32, callbacks=[es])

inception_resnet_rms_val = inception_resnet_rms.evaluate(val_generator)
print("\n")
print("InceptionResNetV2 Model - RMSProp Optimizer Accuracy - ", inception_resnet_rms_val[1]*100)
inception_resnet_rms_val

"""## SGD"""
print("\n")
print("--------------------------------- InceptionResNetV2 Model with SGD Optimizer---------------------------------")
inception_resnet_sgd = InceptionResNet_model
momentum1 = tf.keras.optimizers.SGD(
    learning_rate = 0.01,
    momentum = beta1,
    nesterov = False,
)

inception_resnet_sgd.compile(
    optimizer=momentum1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
history_inception_resnet_sgd = inception_resnet_sgd.fit(train_generator, epochs=50,validation_data=val_generator, batch_size=32, callbacks=[es])

inception_resnet_sgd_val = inception_resnet_sgd.evaluate(val_generator)
print("\n")
print("InceptionResNetV2 Model - SGD Optimizer Accuracy - ", inception_resnet_sgd_val[1]*100)
inception_resnet_sgd_val

"""## Plots"""

import seaborn as sns
classifiers = [inception_resnet_adam_val , inception_resnet_ada_val ,inception_resnet_rms_val ,inception_resnet_sgd_val]
cv_results_res = []
for i in classifiers :
    cv_results_res.append(i[1])
cv_results_res = pd.DataFrame({"Evaluate":cv_results_res,"Network":["resNetAdam","resNetAdagrad","resNetRMS",
"resNetGD"]})

cv_results_res

# use seaborn to create a barplot
sns.set(style="whitegrid")
ax = sns.barplot(x="Network", y="Evaluate", data=cv_results_res)

# add labels to the plot
ax.set_title("Evaluation Scores for Different Optimizers for InceptionResNetV2")
ax.set_xlabel("Network")
ax.set_ylabel("Accuracy")

# display the plot
plt.savefig("outputs/chestXrayDataset/inceptionresnet50_evaluation_scores.png")
plt.show()

"""## Loss Plots"""

# Plot training & validation loss values
plt.plot(history_inception_resnet_adam.history['loss'])
plt.plot(history_inception_resnet_ada.history['loss'])
plt.plot(history_inception_resnet_rms.history['loss'])
plt.plot(history_inception_resnet_sgd.history['loss'])
plt.title('InceptionResNetV2 Model Training Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='upper right')
plt.savefig("outputs/chestXrayDataset/inceptionresnet50_training_loss.png")
plt.show()

# Plot training & validation loss values
plt.plot(history_inception_resnet_adam.history['val_loss'])
plt.plot(history_inception_resnet_ada.history['val_loss'])
plt.plot(history_inception_resnet_rms.history['val_loss'])
plt.plot(history_inception_resnet_sgd.history['val_loss'])
plt.title('InceptionResNetV2 Model Validation Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='upper right')
plt.savefig("outputs/chestXrayDataset/inceptionresnet50_validation_loss.png")
plt.show()

"""## Accuracy Plots"""

# Plot training & validation loss values
plt.plot(history_inception_resnet_adam.history['accuracy'])
plt.plot(history_inception_resnet_ada.history['accuracy'])
plt.plot(history_inception_resnet_rms.history['accuracy'])
plt.plot(history_inception_resnet_sgd.history['accuracy'])
plt.title('InceptionResNetV2 Model Training Accuracy')
plt.ylabel('accuracy')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='lower right')
plt.savefig("outputs/chestXrayDataset/inceptionresnet50_training_accuracy.png")
plt.show()

# Plot training & validation loss values
plt.plot(history_inception_resnet_adam.history['val_accuracy'])
plt.plot(history_inception_resnet_ada.history['val_accuracy'])
plt.plot(history_inception_resnet_rms.history['val_accuracy'])
plt.plot(history_inception_resnet_sgd.history['val_accuracy'])
plt.title('InceptionResNetV2 Model Validation Accuracy')
plt.ylabel('accuracy')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='lower right')
plt.savefig("outputs/chestXrayDataset/inceptionresnet50_validation_accuracy.png")
plt.show()

"""## Whisker Plot"""

import seaborn as sns
import pandas as pd
optimizer =['Adam', 'Adagrad','RMSprop','SGD']
histories =[history_inception_resnet_adam,history_inception_resnet_ada,history_inception_resnet_rms,history_inception_resnet_sgd]
acc_data=[]
for i in range(len(optimizer)):
    acc = histories[i].history['val_accuracy']
    acc_data.append(acc)
  
fig, ax = plt.subplots()
ax.boxplot(acc_data, labels=[str(i) for i in optimizer])
ax.set_ylabel('Accuracy')
ax.set_xlabel('Optimizers')
ax.set_title('InceptionResNetV2 Model - Validation Accuracy by Optimizer')
plt.savefig("outputs/chestXrayDataset/inceptionresnet50_val_acc_whiskerplot.png")
plt.show()

"""# Xception"""
print("\n")
print("--------------------------------- Xception Model ---------------------------------")
from tensorflow.keras.applications.xception import Xception
base_model = Xception(include_top=False, weights='imagenet', input_shape=(img_size, img_size, 3))
base_model.trainable = False

from tensorflow.keras import layers, models
flatten_layer = layers.Flatten()
dense_layer_1 = layers.Dense(50, activation='relu')
dense_layer_2 = layers.Dense(20, activation='relu')
prediction_layer = layers.Dense(2, activation='softmax')

Xception_model = models.Sequential([
    base_model,
    flatten_layer,
    dense_layer_1,
    dense_layer_2,
    prediction_layer
])
Xception_model.summary()

"""## Adam"""
print("\n")
print("--------------------------------- Xception Model with Adam Optimizer---------------------------------")
beta1 = 0.9
beta2 = 0.99
epsilonE = 1e-06

xception_adam = Xception_model
import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping
adam1 = tf.keras.optimizers.Adam(
    learning_rate = 0.001,
    beta_1 = beta1,
    beta_2 = beta2,
    epsilon = epsilonE,
    amsgrad=False,
)

xception_adam.compile(
    optimizer=adam1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
history_xception_adam = xception_adam.fit(train_generator, epochs=50, validation_data=val_generator, batch_size=32, callbacks=[es])

xception_adam_val = xception_adam.evaluate(val_generator)
print("\n")
print("Xception Model - Adam Optimizer Accuracy - ", xception_adam_val[1]*100)
xception_adam_val

"""## Adagrad"""
print("\n")
print("--------------------------------- Xception Model with Adagrad Optimizer---------------------------------")
xception_ada=Xception_model
adagrad1 = tf.keras.optimizers.Adagrad(
    learning_rate = 0.001,
    initial_accumulator_value = 0.1,
    epsilon = epsilonE,
)

xception_ada.compile(
    optimizer=adagrad1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
history_xception_ada = xception_ada.fit(train_generator, epochs=50,validation_data=val_generator, batch_size=32, callbacks=[es])

xception_ada_val = xception_ada.evaluate(val_generator)
print("\n")
print("Xception Model - Adagrad Optimizer Accuracy - ", xception_ada_val[1]*100)
xception_ada_val

"""## RMSProp"""
print("\n")
print("--------------------------------- Xception Model with RMSProp Optimizer---------------------------------")
# RMSProp
xception_rms = Xception_model
rmsprop1 = tf.keras.optimizers.RMSprop(
    learning_rate = 0.001,
    rho = 0.9,
    momentum = 0.0,
    epsilon = epsilonE,
    centered=False,
)
xception_rms.compile(
    optimizer=rmsprop1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
history_xception_rms = xception_rms.fit(train_generator, epochs=50,validation_data=val_generator, batch_size=32, callbacks=[es])

xception_rms_val = xception_rms.evaluate(val_generator)
print("\n")
print("Xception Model - RMSProp Optimizer Accuracy - ", xception_rms_val[1]*100)
xception_rms_val

"""## SGD"""
print("\n")
print("--------------------------------- Xception Model with SGD Optimizer---------------------------------")
xception_sgd = Xception_model
momentum1 = tf.keras.optimizers.SGD(
    learning_rate = 0.01,
    momentum = beta1,
    nesterov = False,
)

xception_sgd.compile(
    optimizer=momentum1,
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)
history_xception_sgd = xception_sgd.fit(train_generator, epochs=50,validation_data=val_generator, batch_size=32, callbacks=[es])

xception_sgd_val = xception_sgd.evaluate(val_generator)
print("\n")
print("Xception Model - SGD Optimizer Accuracy - ", xception_sgd_val[1]*100)
xception_sgd_val

"""## Plots"""

import seaborn as sns
classifiers = [xception_adam_val , xception_ada_val ,xception_rms_val ,xception_sgd_val]
cv_results_res = []
for i in classifiers :
    cv_results_res.append(i[1])
cv_results_res = pd.DataFrame({"Evaluate":cv_results_res,"Network":["xcepAdam","xcepAdagrad","xcepRMS",
"xcepSGD"]})

cv_results_res

# use seaborn to create a barplot
sns.set(style="whitegrid")
ax = sns.barplot(x="Network", y="Evaluate", data=cv_results_res)

# add labels to the plot
ax.set_title("Evaluation Scores for Different Optimizers for Xception")
ax.set_xlabel("Network")
ax.set_ylabel("Accuracy")

# display the plot
plt.savefig("outputs/chestXrayDataset/xception_optimizer_evaluation.png")
plt.show()

"""## Loss Plots"""

# Plot training & validation loss values
plt.plot(history_xception_adam.history['loss'])
plt.plot(history_xception_ada.history['loss'])
plt.plot(history_xception_rms.history['loss'])
plt.plot(history_xception_sgd.history['loss'])
plt.title('Xception Model Training Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='upper right')
plt.savefig("outputs/chestXrayDataset/xception_training_loss.png")
plt.show()

# Plot training & validation loss values
plt.plot(history_xception_adam.history['val_loss'])
plt.plot(history_xception_ada.history['val_loss'])
plt.plot(history_xception_rms.history['val_loss'])
plt.plot(history_xception_sgd.history['val_loss'])
plt.title('Xception Model Validation Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='upper right')
plt.savefig("outputs/chestXrayDataset/xception_validation_loss.png")
plt.show()

"""## Accuracy Plots"""

# Plot training & validation loss values
plt.plot(history_xception_adam.history['accuracy'])
plt.plot(history_xception_ada.history['accuracy'])
plt.plot(history_xception_rms.history['accuracy'])
plt.plot(history_xception_sgd.history['accuracy'])
plt.title('Xception Model Training Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='lower right')
plt.savefig("outputs/chestXrayDataset/xception_training_accuracy.png")
plt.show()

# Plot training & validation loss values
plt.plot(history_xception_adam.history['val_accuracy'])
plt.plot(history_xception_ada.history['val_accuracy'])
plt.plot(history_xception_rms.history['val_accuracy'])
plt.plot(history_xception_sgd.history['val_accuracy'])
plt.title('Xception Model Validation Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Adam', 'Adagrad','RMSprop','SGD'], loc='lower right')
plt.savefig("outputs/chestXrayDataset/xception_validation_accuracy.png")
plt.show()

## Whisker Plot

import seaborn as sns
import pandas as pd
optimizer =['Adam', 'Adagrad','RMSprop','SGD']
histories =[history_xception_adam,history_xception_ada,history_xception_rms,history_xception_sgd]
acc_data=[]
for i in range(len(optimizer)):
    acc = histories[i].history['val_accuracy']
    acc_data.append(acc)
  
fig, ax = plt.subplots()
ax.boxplot(acc_data, labels=[str(i) for i in optimizer])
ax.set_ylabel('Accuracy')
ax.set_xlabel('Optimizers')
ax.set_title('Xception Model - Validation Accuracy by Optimizer')
plt.savefig("outputs/chestXrayDataset/xception_val_acc_whiskerplot.png")
plt.show()
